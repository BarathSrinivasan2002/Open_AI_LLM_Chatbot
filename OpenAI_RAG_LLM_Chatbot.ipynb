{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pyttsx3\n",
    "import pyaudio\n",
    "import wave\n",
    "import random\n",
    "from pinecone import Pinecone\n",
    "from openai import OpenAI\n",
    "\n",
    "openai.api_key = \"sk-svcacct-40OsNDk5Z7NQe25GAoyV8HCAVizvFOSkAeC2fHNNnPqj3UdmyZeMVfRcMnhg4ZT3BlbkFJ-k-oq6yKeb5rcb0hTr8Ybiy9HG3Q_PSecyFFtg9mmXXedMk31urv5ykV7DUH8A\"\n",
    "pinecone_api_key = \"pcsk_gToqV_QsdweU7dicHERcFNnnYhgo6hU1Dntnue5JWyuRV3ij8gsmqw8tvRS1syDshVPsj\"\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "index_name = \"virtual-clinic\"\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "engine = pyttsx3.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def record_audio(file_path, duration=5):\n",
    "    \"\"\"Record audio and save it to the given file path.\"\"\"\n",
    "    chunk = 1024\n",
    "    sample_format = pyaudio.paInt16\n",
    "    channels = 1\n",
    "    rate = 44100\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    print(\"Recording...\")\n",
    "    stream = p.open(format=sample_format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=chunk)\n",
    "    frames = []\n",
    "\n",
    "    for _ in range(0, int(rate / chunk * duration)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    with wave.open(file_path, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(sample_format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "    print(\"Recording finished.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to transcribe audio\n",
    "def transcribe_audio(file_path):\n",
    "    \"\"\"Transcribe audio to text using OpenAI Whisper.\"\"\"\n",
    "    client = OpenAI(api_key =\"sk-svcacct-40OsNDk5Z7NQe25GAoyV8HCAVizvFOSkAeC2fHNNnPqj3UdmyZeMVfRcMnhg4ZT3BlbkFJ-k-oq6yKeb5rcb0hTr8Ybiy9HG3Q_PSecyFFtg9mmXXedMk31urv5ykV7DUH8A\")\n",
    "    with open(file_path, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "          model=\"whisper-1\", \n",
    "          file=audio_file\n",
    "        )\n",
    "    return transcription.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to speak text\n",
    "def speak_text(text):\n",
    "    \"\"\"Convert text to speech.\"\"\"\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Profile: You are a 10-year-old child speaking to a doctor.\n"
     ]
    }
   ],
   "source": [
    "def query_pinecone(query_text):\n",
    "    \"\"\"Query Pinecone for patient information.\"\"\"\n",
    "    client = OpenAI(api_key=\"sk-svcacct-40OsNDk5Z7NQe25GAoyV8HCAVizvFOSkAeC2fHNNnPqj3UdmyZeMVfRcMnhg4ZT3BlbkFJ-k-oq6yKeb5rcb0hTr8Ybiy9HG3Q_PSecyFFtg9mmXXedMk31urv5ykV7DUH8A\")\n",
    "\n",
    "    \n",
    "    response = client.embeddings.create(\n",
    "        input=query_text,\n",
    "        model=\"text-embedding-3-small\" \n",
    "    )\n",
    "    \n",
    "    query_embedding = response.data[0].embedding \n",
    "    try:\n",
    "        result = index.query(\n",
    "            vector=query_embedding,\n",
    "            top_k=1,\n",
    "            include_metadata=True\n",
    "        )\n",
    "        if result[\"matches\"]:\n",
    "            match = result[\"matches\"][0]\n",
    "            metadata = match.get(\"metadata\", {})\n",
    "            return {\n",
    "                \"id\": match[\"id\"],\n",
    "                \"score\": match[\"score\"],\n",
    "                \"allergy\": metadata.get(\"allergy\", \"None\"),\n",
    "                \"medicine_to_avoid\": metadata.get(\"medicine_to_avoid\", \"None\"),\n",
    "                \"food_to_avoid\": metadata.get(\"food_to_avoid\", \"None\")\n",
    "            }\n",
    "    except Exception as e:\n",
    "        print(f\"Error querying Pinecone: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Patient profiles\n",
    "patient_profiles = {\n",
    "    \"child\": \"You are a 10-year-old child speaking to a doctor.\",\n",
    "    \"elderly\": \"You are a 70-year-old patient who might not understand medical jargon.\",\n",
    "    \"default\": \"You are a 30-year-old patient responding to a doctor's questions.\",\n",
    "    \"teenager\": \"You are a 16-year-old who might feel hesitant to share details openly.\",\n",
    "    \"busy_adult\": \"You are a busy professional who wants a quick resolution to health issues.\"\n",
    "}\n",
    "selected_profile = random.choice(list(patient_profiles.values()))\n",
    "print(f\"Selected Profile: {selected_profile}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Virtual Clinic Simulation. Speak your input into the microphone. Say 'quit' to exit.\n",
      "Recording...\n",
      "Recording finished.\n",
      "Doctor (Transcribed): Hi, how are you today?\n",
      "Matched Patient Data: {'id': 'elderly1', 'score': 0.212654352, 'allergy': 'Shellfish', 'medicine_to_avoid': 'Statins', 'food_to_avoid': 'Shellfish dishes'}\n",
      "Patient: Hi, I'm doing okay, thank you. I have an allergy to shellfish, so I make sure not to eat any shellfish dishes. Also, I need to avoid medicines like statins. I just wanted to let you know so we can stay safe!\n",
      "Recording...\n",
      "Recording finished.\n",
      "Doctor (Transcribed): Quit\n",
      "Exiting simulation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def virtual_clinic():\n",
    "    \"\"\"Run the Virtual Clinic Simulation.\"\"\"\n",
    "    print(\"Starting Virtual Clinic Simulation. Speak your input into the microphone. Say 'quit' to exit.\")\n",
    "    while True:\n",
    "        doctor_audio_path = \"C:/Users/User/Python_/doctor_input.wav\"\n",
    "        record_audio(doctor_audio_path, duration=5)\n",
    "\n",
    "        transcribed_input = transcribe_audio(doctor_audio_path)\n",
    "        print(\"Doctor (Transcribed):\", transcribed_input)\n",
    "\n",
    "        if \"quit\" in transcribed_input.lower():\n",
    "            print(\"Exiting simulation.\")\n",
    "            break\n",
    "\n",
    "        patient_info = query_pinecone(transcribed_input)\n",
    "        if patient_info:\n",
    "            print(f\"Matched Patient Data: {patient_info}\")\n",
    "            pinecone_data = (f\"Allergy: {patient_info['allergy']}, \"\n",
    "                             f\"Medicine to avoid: {patient_info['medicine_to_avoid']}, \"\n",
    "                             f\"Food to avoid: {patient_info['food_to_avoid']}\")\n",
    "        else:\n",
    "            pinecone_data = \"No relevant patient data found.\"\n",
    "\n",
    "        user_message = f\"{selected_profile}\\nDoctor: {transcribed_input}\\nPatient Info: {pinecone_data}\"\n",
    "        client = OpenAI(api_key =\"sk-svcacct-40OsNDk5Z7NQe25GAoyV8HCAVizvFOSkAeC2fHNNnPqj3UdmyZeMVfRcMnhg4ZT3BlbkFJ-k-oq6yKeb5rcb0hTr8Ybiy9HG3Q_PSecyFFtg9mmXXedMk31urv5ykV7DUH8A\")\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"o1-mini-2024-09-12\",\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "        patient_response = completion.choices[0].message.content\n",
    "        print(\"Patient:\", patient_response)\n",
    "\n",
    "        speak_text(patient_response)\n",
    "\n",
    "virtual_clinic()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## This is for RAG vector DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index creation error: (409)\n",
      "Reason: Conflict\n",
      "HTTP response headers: HTTPHeaderDict({'content-type': 'text/plain; charset=utf-8', 'access-control-allow-origin': '*', 'vary': 'origin,access-control-request-method,access-control-request-headers', 'access-control-expose-headers': '*', 'x-pinecone-api-version': '2024-04', 'X-Cloud-Trace-Context': '8410c37f0f9a632e56879b8709bb75ec', 'Date': 'Thu, 28 Nov 2024 22:13:08 GMT', 'Server': 'Google Frontend', 'Content-Length': '85', 'Via': '1.1 google', 'Alt-Svc': 'h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000'})\n",
      "HTTP response body: {\"error\":{\"code\":\"ALREADY_EXISTS\",\"message\":\"Resource  already exists\"},\"status\":409}\n",
      "\n",
      "Error generating embeddings or inserting into Pinecone: \n",
      "\n",
      "You tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Match ID: child1, Score: 0.511479318\n",
      "Allergy: Peanuts, Medicine to avoid: Ibuprofen, Food to avoid: Peanut butter\n",
      "Match ID: default2, Score: 0.464543909\n",
      "Allergy: Dust mites, Medicine to avoid: Beta blockers, Food to avoid: Dairy products\n",
      "Match ID: elderly2, Score: 0.451170117\n",
      "Allergy: Latex, Medicine to avoid: ACE inhibitors, Food to avoid: High-sodium foods\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(\n",
    "    api_key=\"pcsk_gToqV_QsdweU7dicHERcFNnnYhgo6hU1Dntnue5JWyuRV3ij8gsmqw8tvRS1syDshVPsj\"  # Replace with your Pinecone API key\n",
    ")\n",
    "\n",
    "index_name = \"virtual-clinic\"\n",
    "\n",
    "try:\n",
    "    if index_name not in pc.list_indexes():\n",
    "        pc.create_index(\n",
    "            name=index_name,\n",
    "            dimension=1536, \n",
    "            metric=\"cosine\",  \n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "        print(f\"Index '{index_name}' created successfully.\")\n",
    "    else:\n",
    "        print(f\"Index '{index_name}' already exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Index creation error: {e}\")\n",
    "\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "patient_records = [\n",
    "    {\"id\": \"child1\", \"text\": \"I feel tired and have a sore throat. I don't want to go to school.\",\n",
    "     \"allergy\": \"Peanuts\", \"medicine_to_avoid\": \"Ibuprofen\", \"food_to_avoid\": \"Peanut butter\"},\n",
    "    {\"id\": \"child2\", \"text\": \"I hurt my arm while playing soccer yesterday.\",\n",
    "     \"allergy\": \"None\", \"medicine_to_avoid\": \"None\", \"food_to_avoid\": \"None\"},\n",
    "    {\"id\": \"elderly1\", \"text\": \"I’ve been feeling dizzy and weak lately. I have trouble climbing stairs.\",\n",
    "     \"allergy\": \"Shellfish\", \"medicine_to_avoid\": \"Statins\", \"food_to_avoid\": \"Shellfish dishes\"},\n",
    "    {\"id\": \"elderly2\", \"text\": \"I think my blood pressure medication might be making me feel light-headed.\",\n",
    "     \"allergy\": \"Latex\", \"medicine_to_avoid\": \"ACE inhibitors\", \"food_to_avoid\": \"High-sodium foods\"},\n",
    "    {\"id\": \"default1\", \"text\": \"I’ve had a persistent headache for two days and some mild nausea.\",\n",
    "     \"allergy\": \"Pollen\", \"medicine_to_avoid\": \"Aspirin\", \"food_to_avoid\": \"Raw honey\"},\n",
    "    {\"id\": \"default2\", \"text\": \"I feel shortness of breath and chest tightness during physical activities.\",\n",
    "     \"allergy\": \"Dust mites\", \"medicine_to_avoid\": \"Beta blockers\", \"food_to_avoid\": \"Dairy products\"},\n",
    "    {\"id\": \"teenager1\", \"text\": \"I have acne and feel self-conscious about it. What can I do to treat it?\",\n",
    "     \"allergy\": \"None\", \"medicine_to_avoid\": \"Steroids\", \"food_to_avoid\": \"Fried foods\"},\n",
    "    {\"id\": \"teenager2\", \"text\": \"I’ve been feeling anxious about exams and can’t sleep well.\",\n",
    "     \"allergy\": \"None\", \"medicine_to_avoid\": \"None\", \"food_to_avoid\": \"Caffeinated drinks\"},\n",
    "    {\"id\": \"busy_adult1\", \"text\": \"I need a quick remedy for this cold. I can’t afford to take time off work.\",\n",
    "     \"allergy\": \"Aspirin\", \"medicine_to_avoid\": \"NSAIDs\", \"food_to_avoid\": \"Alcohol\"},\n",
    "    {\"id\": \"busy_adult2\", \"text\": \"I have neck pain from working long hours at a desk.\",\n",
    "     \"allergy\": \"None\", \"medicine_to_avoid\": \"None\", \"food_to_avoid\": \"None\"}\n",
    "]\n",
    "\n",
    "openai.api_key = \"sk-svcacct-40OsNDk5Z7NQe25GAoyV8HCAVizvFOSkAeC2fHNNnPqj3UdmyZeMVfRcMnhg4ZT3BlbkFJ-k-oq6yKeb5rcb0hTr8Ybiy9HG3Q_PSecyFFtg9mmXXedMk31urv5ykV7DUH8A\"\n",
    "\n",
    "try:\n",
    "    for record in patient_records:\n",
    "        combined_text = (f\"{record['text']} Allergy: {record.get('allergy', 'None')}, \"\n",
    "                         f\"Medicine to avoid: {record.get('medicine_to_avoid', 'None')}, \"\n",
    "                         f\"Food to avoid: {record.get('food_to_avoid', 'None')}\")\n",
    "        embedding = openai.Embedding.create(\n",
    "            input=combined_text,\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )[\"data\"][0][\"embedding\"]\n",
    "\n",
    "        \n",
    "        index.upsert([{\"id\": record[\"id\"], \"values\": embedding, \"metadata\": record}])\n",
    "        print(f\"Record {record['id']} inserted into Pinecone.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error generating embeddings or inserting into Pinecone: {e}\")\n",
    "query_text = \"What should a patient allergic to peanuts avoid?\"\n",
    "client = OpenAI(api_key=\"sk-svcacct-40OsNDk5Z7NQe25GAoyV8HCAVizvFOSkAeC2fHNNnPqj3UdmyZeMVfRcMnhg4ZT3BlbkFJ-k-oq6yKeb5rcb0hTr8Ybiy9HG3Q_PSecyFFtg9mmXXedMk31urv5ykV7DUH8A\")\n",
    "# Generate embeddings\n",
    "query_embedding = client.embeddings.create(\n",
    "    input=query_text,\n",
    "    model=\"text-embedding-3-small\" \n",
    ").data[0].embedding  \n",
    "\n",
    "try:\n",
    "    result = index.query(\n",
    "        vector=query_embedding,\n",
    "        top_k=3,\n",
    "        include_metadata=True\n",
    "    )\n",
    "    for match in result[\"matches\"]:\n",
    "        if \"metadata\" in match:\n",
    "            metadata = match[\"metadata\"]\n",
    "            print(f\"Match ID: {match['id']}, Score: {match['score']}\")\n",
    "            print(f\"Allergy: {metadata['allergy']}, Medicine to avoid: {metadata['medicine_to_avoid']}, Food to avoid: {metadata['food_to_avoid']}\")\n",
    "        else:\n",
    "            print(f\"Match ID: {match['id']}, Score: {match['score']}, Metadata not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error querying Pinecone: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\user\\anaconda3\\lib\\site-packages (0.0.13)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (3.11.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain_community) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain_community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain_community) (1.10.19)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain_community) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.9->langchain_community) (2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.9->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (0.4.3)\n",
      "Requirement already satisfied: langchain in c:\\users\\user\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (3.11.8)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.0.13)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.1.23)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (0.0.87)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (1.10.19)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.23.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain) (3.5.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.9->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Obtaining dependency information for pypdf from https://files.pythonhosted.org/packages/04/fc/6f52588ac1cb4400a7804ef88d0d4e00cfe57a7ac6793ec3b00de5a8758b/pypdf-5.1.0-py3-none-any.whl.metadata\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "   ---------------------------------------- 0.0/298.0 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 92.2/298.0 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  297.0/298.0 kB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 298.0/298.0 kB 3.1 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community\n",
    "!pip install langchain\n",
    "\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "fitter 1.7.0 requires numpy<2.0.0,>=1.20.0, but you have numpy 2.1.3 which is incompatible.\n",
      "langchain 0.1.1 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\n",
      "langchain-community 0.0.13 requires numpy<2,>=1, but you have numpy 2.1.3 which is incompatible.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 2.1.3 which is incompatible.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.1.3 which is incompatible.\n",
      "tensorflow-intel 2.16.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.1.3 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet faiss-cpu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='[ \\n    { \\n        \"id\": \"child1\", \\n        \"text\": \"I have a skin rash. What could it be and how should I treat it?\", \\n        \"allergy\": \"None\", \\n        \"medicine_to_avoid\": \"None\", \\n        \"food_to_avoid\": \"Sugary and processed foods\" \\n    }, \\n    { \\n        \"id\": \" child2\", \\n        \"text\": \"I have small bumps on my body  and face What could be causing this?\", \\n        \"allergy\": \"None\", \\n        \"medicine_to_avoid\": \" Steroids\", \\n        \"food_to_avoid\": \" None \" \\n    }, \\n    { \\n        \"id\": \"child3\", \\n        \"text\": \"I feel tired and have a sore throat”, \\n        \"allergy\": \"Peanuts\", \\n        \"medicine_to_avoid\": \"Ibuprofen\", \\n        \"food_to_avoid\": \"Peanut products\" \\n    }, \\n \\n    { \\n        \"id\": \"default1\", \\n        \"text\": \"I experience allergies frequently. Could you explain common triggers and treatments?\", \\n        \"allergy\": \"Shellfish\", \\n        \"medicine_to_avoid\": \"Statins\", \\n        \"food_to_avoid\": \"Shellfish dishes\"', metadata={'source': 'C:\\\\Users\\\\User\\\\Python_\\\\problems-solutions .pdf', 'page': 0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = (\n",
    "    \"C:\\\\Users\\\\User\\\\Python_\\\\problems-solutions .pdf\"\n",
    ")\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key:········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai\n",
      "  Obtaining dependency information for langchain_openai from https://files.pythonhosted.org/packages/c3/36/a5426bf8195af460aefefe9c15bbf091a549cfd9cb243efd167d6a7b3a42/langchain_openai-0.2.10-py3-none-any.whl.metadata\n",
      "  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.21 (from langchain_openai)\n",
      "  Obtaining dependency information for langchain-core<0.4.0,>=0.3.21 from https://files.pythonhosted.org/packages/9b/50/e0bd90fc481d1cc8c2039ad6161b20fc8e396a7cba6064a4f1e8e5afea62/langchain_core-0.3.21-py3-none-any.whl.metadata\n",
      "  Downloading langchain_core-0.3.21-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.54.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain_openai) (1.55.3)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Obtaining dependency information for tiktoken<1,>=0.7 from https://files.pythonhosted.org/packages/1e/86/eea2309dc258fb86c7d9b10db536434fc16420feaa3b6113df18b23db7c2/tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4.0,>=0.3.21->langchain_openai)\n",
      "  Obtaining dependency information for langsmith<0.2.0,>=0.1.125 from https://files.pythonhosted.org/packages/de/f0/63b06b99b730b9954f8709f6f7d9b8d076fa0a973e472efe278089bde42b/langsmith-0.1.147-py3-none-any.whl.metadata\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (23.2)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core<0.4.0,>=0.3.21->langchain_openai)\n",
      "  Obtaining dependency information for pydantic<3.0.0,>=2.5.2 from https://files.pythonhosted.org/packages/d5/74/da832196702d0c56eb86b75bfa346db9238617e29b0b7ee3b8b4eccfe654/pydantic-2.10.2-py3-none-any.whl.metadata\n",
      "  Using cached pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.21->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.54.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2022.7.9)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.54.0->langchain_openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.54.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain_openai) (2.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai)\n",
      "  Obtaining dependency information for orjson<4.0.0,>=3.9.14 from https://files.pythonhosted.org/packages/83/fe/babf08842b989acf4c46103fefbd7301f026423fab47e6f3ba07b54d7837/orjson-3.10.12-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading orjson-3.10.12-cp311-none-win_amd64.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 42.9/42.9 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.21->langchain_openai) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai) (0.6.0)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.21->langchain_openai)\n",
      "  Obtaining dependency information for pydantic-core==2.27.1 from https://files.pythonhosted.org/packages/6a/fe/4e0e63c418c1c76e33974a05266e5633e879d4061f9533b1706a86f77d5b/pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (1.26.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.54.0->langchain_openai) (0.4.6)\n",
      "Downloading langchain_openai-0.2.10-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.6/50.6 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.21-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.5 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 225.3/409.5 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.5/409.5 kB 6.3 MB/s eta 0:00:00\n",
      "Using cached tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "   ---------------------------------------- 0.0/311.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 311.8/311.8 kB 9.7 MB/s eta 0:00:00\n",
      "Using cached pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp311-none-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.0 MB 31.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.6/2.0 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 15.8 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.12-cp311-none-win_amd64.whl (135 kB)\n",
      "   ---------------------------------------- 0.0/135.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 135.1/135.1 kB 7.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pydantic-core, orjson, tiktoken, pydantic, langsmith, langchain-core, langchain_openai\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.14.6\n",
      "    Uninstalling pydantic_core-2.14.6:\n",
      "      Successfully uninstalled pydantic_core-2.14.6\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.4.0\n",
      "    Uninstalling tiktoken-0.4.0:\n",
      "      Successfully uninstalled tiktoken-0.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\User\\\\anaconda3\\\\Lib\\\\site-packages\\\\~iktoken\\\\_tiktoken.cp311-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_community\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      4\u001b[0m faiss_index \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(pages, OpenAIEmbeddings())\n\u001b[0;32m      5\u001b[0m docs \u001b[38;5;241m=\u001b[39m faiss_index\u001b[38;5;241m.\u001b[39msimilarity_search(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the patients allergies?\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain_openai'"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "faiss_index = FAISS.from_documents(pages, OpenAIEmbeddings())\n",
    "docs = faiss_index.similarity_search(\"What are the patients allergies?\", k=2)\n",
    "for doc in docs:\n",
    "    print(str(doc.metadata[\"page\"]) + \":\", doc.page_content[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
